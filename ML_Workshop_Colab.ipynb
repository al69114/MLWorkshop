{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UGA Hacks11 - Intro to Machine Learning Workshop\n",
    "## Linear Regression from Scratch\n",
    "\n",
    "**Workshop Goals:**\n",
    "- Understand what Machine Learning is\n",
    "- Learn the ML workflow\n",
    "- Implement Linear Regression from scratch\n",
    "- Use scikit-learn for ML algorithms\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is Machine Learning?\n",
    "\n",
    "**Machine Learning** involves creating models that learn from data to make predictions on new data.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **AI**: Enabling computers to perform human-like tasks\n",
    "- **ML**: Subset of AI that learns patterns from data\n",
    "- **Types of ML**:\n",
    "  - Supervised (labeled data): Classification, Regression\n",
    "  - Unsupervised (unlabeled data): Clustering\n",
    "  - Reinforcement Learning: Learn through trial and error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Install Required Libraries\n",
    "\n",
    "Run this cell to install all necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install numpy matplotlib scikit-learn pandas seaborn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Linear Regression Theory\n",
    "\n",
    "### What is Linear Regression?\n",
    "\n",
    "Linear regression finds a linear relationship between input (X) and output (y):\n",
    "\n",
    "**Equation:** `y = mx + b`\n",
    "\n",
    "- **m** (slope): How much y changes when x increases\n",
    "- **b** (intercept): Value of y when x = 0\n",
    "\n",
    "### Goal:\n",
    "Find the best values of m and b that minimize prediction error!\n",
    "\n",
    "### How?\n",
    "**Gradient Descent** - An optimization algorithm that iteratively adjusts m and b\n",
    "\n",
    "### Evaluation Metric:\n",
    "**Mean Squared Error (MSE)** - Measures average squared difference between actual and predicted values\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Lower MSE = Better model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Generate Sample Data\n",
    "\n",
    "Let's create synthetic data that follows a linear pattern with some noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=100, noise=10, slope=2.5, intercept=5):\n",
    "    \"\"\"\n",
    "    Generate synthetic linear data\n",
    "    True relationship: y = slope * x + intercept + noise\n",
    "    \"\"\"\n",
    "    X = np.random.rand(n_samples) * 100  # Random values between 0 and 100\n",
    "    y = slope * X + intercept + np.random.randn(n_samples) * noise\n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "X, y = generate_data(n_samples=100, noise=10)\n",
    "\n",
    "print(f\"Generated {len(X)} data points\")\n",
    "print(f\"X range: [{X.min():.2f}, {X.max():.2f}]\")\n",
    "print(f\"y range: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.5, color='blue')\n",
    "plt.xlabel('X (Independent Variable)')\n",
    "plt.ylabel('y (Dependent Variable)')\n",
    "plt.title('Generated Dataset')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Linear Regression from Scratch\n",
    "\n",
    "Now let's implement Linear Regression using Gradient Descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionScratch:\n",
    "    \"\"\"Linear Regression using Gradient Descent\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.0001, iterations=500):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.slope = 0\n",
    "        self.intercept = 0\n",
    "        self.mse_history = []\n",
    "    \n",
    "    def calculate_mse(self, y_true, y_pred):\n",
    "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model using Gradient Descent\"\"\"\n",
    "        n = len(X)\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            # Make predictions\n",
    "            y_pred = self.slope * X + self.intercept\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mse = self.calculate_mse(y, y_pred)\n",
    "            self.mse_history.append(mse)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            slope_gradient = -(2/n) * np.sum(X * (y - y_pred))\n",
    "            intercept_gradient = -(2/n) * np.sum(y - y_pred)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.slope -= self.learning_rate * slope_gradient\n",
    "            self.intercept -= self.learning_rate * intercept_gradient\n",
    "            \n",
    "            # Print progress\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Iteration {i+1}/{self.iterations} - MSE: {mse:.4f}\")\n",
    "        \n",
    "        print(f\"\\nâœ… Training Complete!\")\n",
    "        print(f\"Final equation: y = {self.slope:.4f}x + {self.intercept:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return self.slope * X + self.intercept\n",
    "\n",
    "print(\"âœ… LinearRegressionScratch class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Train the Model\n",
    "\n",
    "Let's train our model on the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "# Create and train model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model = LinearRegressionScratch(learning_rate=0.0001, iterations=500)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Visualize Results\n",
    "\n",
    "Let's see how well our model learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Best fit line\n",
    "axes[0].scatter(X_train, y_train, alpha=0.5, color='blue', label='Training Data')\n",
    "axes[0].plot(X_train, y_pred_train, color='red', linewidth=2, \n",
    "             label=f'y = {model.slope:.2f}x + {model.intercept:.2f}')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_title('Linear Regression: Best Fit Line')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: MSE convergence\n",
    "axes[1].plot(model.mse_history, color='green', linewidth=2)\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Mean Squared Error')\n",
    "axes[1].set_title('Training Progress: MSE Convergence')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Predictions vs Actual\n",
    "axes[2].scatter(y_test, y_pred_test, alpha=0.5, color='purple')\n",
    "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[2].set_xlabel('Actual Values')\n",
    "axes[2].set_ylabel('Predicted Values')\n",
    "axes[2].set_title('Predictions vs Actual (Test Set)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate test MSE\n",
    "test_mse = model.calculate_mse(y_test, y_pred_test)\n",
    "print(f\"\\nðŸ“Š Test Set MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Using Scikit-Learn\n",
    "\n",
    "Now let's see how to do the same thing with scikit-learn (much easier!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train sklearn model\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Make predictions\n",
    "sklearn_pred = sklearn_model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "sklearn_mse = mean_squared_error(y_test, sklearn_pred)\n",
    "sklearn_r2 = r2_score(y_test, sklearn_pred)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"SCIKIT-LEARN LINEAR REGRESSION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Slope: {sklearn_model.coef_[0]:.4f}\")\n",
    "print(f\"Intercept: {sklearn_model.intercept_:.4f}\")\n",
    "print(f\"Test MSE: {sklearn_mse:.4f}\")\n",
    "print(f\"RÂ² Score: {sklearn_r2:.4f} (closer to 1 is better)\")\n",
    "\n",
    "# Compare with our implementation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON: Our Model vs Scikit-Learn\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Our Model     - Slope: {model.slope:.4f}, Intercept: {model.intercept:.4f}, MSE: {test_mse:.4f}\")\n",
    "print(f\"Scikit-Learn  - Slope: {sklearn_model.coef_[0]:.4f}, Intercept: {sklearn_model.intercept_:.4f}, MSE: {sklearn_mse:.4f}\")\n",
    "print(\"\\nâœ… Our implementation gives similar results to sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Try with Real Data\n",
    "\n",
    "Let's use a real dataset - California Housing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset: California Housing\")\n",
    "print(f\"Samples: {housing.data.shape[0]}\")\n",
    "print(f\"Features: {housing.data.shape[1]}\")\n",
    "print(f\"Feature names: {housing.feature_names}\")\n",
    "print(f\"Target: House value (in $100,000s)\\n\")\n",
    "\n",
    "# Use just one feature for visualization (median income)\n",
    "X_housing = housing.data[:, 0].reshape(-1, 1)  # Median income\n",
    "y_housing = housing.target\n",
    "\n",
    "# Split data\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "real_model = LinearRegression()\n",
    "real_model.fit(X_train_h, y_train_h)\n",
    "\n",
    "# Predict\n",
    "y_pred_h = real_model.predict(X_test_h)\n",
    "\n",
    "# Evaluate\n",
    "mse_h = mean_squared_error(y_test_h, y_pred_h)\n",
    "r2_h = r2_score(y_test_h, y_pred_h)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"MSE: {mse_h:.4f}\")\n",
    "print(f\"RÂ² Score: {r2_h:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test_h, y_test_h, alpha=0.3)\n",
    "plt.plot(X_test_h, y_pred_h, 'r-', linewidth=2)\n",
    "plt.xlabel('Median Income')\n",
    "plt.ylabel('House Value ($100k)')\n",
    "plt.title('California Housing: Income vs Price')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test_h, y_pred_h, alpha=0.3)\n",
    "plt.plot([y_test_h.min(), y_test_h.max()], [y_test_h.min(), y_test_h.max()],\n",
    "         'r--', linewidth=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Predictions vs Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Exercises for You!\n",
    "\n",
    "Try these challenges:\n",
    "\n",
    "### Challenge 1: Tune Hyperparameters\n",
    "Modify the learning rate and iterations in our scratch implementation. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Try different learning_rate values: 0.001, 0.00001, 0.1\n",
    "# Try different iteration values: 100, 1000, 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Load Your Own Dataset\n",
    "Try loading a dataset from the suggestions in DATASET_SUGGESTIONS.md!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Try loading Iris, Wine, or Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Try Other Algorithms\n",
    "Explore Decision Trees, Random Forests, or K-Means clustering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we learned:**\n",
    "1. âœ… What Machine Learning is and types of ML\n",
    "2. âœ… The ML workflow: Data â†’ Train â†’ Predict â†’ Evaluate\n",
    "3. âœ… Linear Regression from scratch using Gradient Descent\n",
    "4. âœ… Mean Squared Error (MSE) for evaluation\n",
    "5. âœ… Using scikit-learn for ML\n",
    "6. âœ… Applying ML to real datasets\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore more datasets (see DATASET_SUGGESTIONS.md)\n",
    "- Try other algorithms (Classification, Clustering)\n",
    "- Participate in Kaggle competitions\n",
    "- Build ML projects for your hackathon!\n",
    "\n",
    "**Resources:**\n",
    "- Scikit-learn docs: https://scikit-learn.org/\n",
    "- Kaggle Learn: https://www.kaggle.com/learn\n",
    "- Google Colab: https://colab.research.google.com/\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulations! You've completed the ML workshop!\n",
    "\n",
    "**Good luck with UGA Hacks11! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
